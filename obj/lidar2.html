<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<title> Lidar simulation - case 2 </title>
<style type="text/css">
    <!--
     body {color: #000000; background: #ffffff;
           font-family: verdana, arial, helvetica, times new roman;
           font-size: small;}
     h1 {font-family: courier new, courier;}
     h2 {font-family: courier new, courier;}
     tt {font-family: courier new, courier;}
    -->
</style>
</head>

<body>
[<a href="lidar1.html">previous</a>] [<a href="lidar3.html">next</a>]
<br>

<h1 align="center">Simple object lidar test: reflectance simulation</h1>
<p>
<hr>
<h2>Camera and light files</h2>

To run a simple lidar test, we consider a simple scene object <a href="test.obj"><tt>test.obj</tt></a>, described in detail in <a href="lidar1.html">the previous page</a>.

Before proceeding with a lidar simulation, we first need to understand ow to use (and interpret) the results of a non time-resolved signal.<p>


We first need to define the properties of the 'camera' (receiver) and 'light' source. The simplest form of this is of the form:<p>

<h3><a href="camera1.dat">Camera</a></h3>
<tt>
<span>
<br>
camera {<br>
&nbsp;camera.name  = "simple camera";<br>
<br>
# geometry<br>
&nbsp;geometry.perspective = TRUE;<br>
&nbsp;geometry.idealArea = 100000<br>
&nbsp;geometry.azimuth = 0.0;<br>
&nbsp;geometry.zenith = 0.0;<br>
&nbsp;geometry.twist = 0.0;<br>
&nbsp;geometry.lookAt = 0, 0, 0;<br>
&nbsp;geometry.boomLength = 10000.;<br>
<br>
&nbsp;samplingCharacteristics.nPixels = 262144;<br>
&nbsp;samplingCharacteristics.rpp = 64;<br>
<br>  
&nbsp;result.samplingImage = "cameraImage.hips"<br>
<br>
&nbsp;result.integral.mode = "scattering order"<br>
<br>
&nbsp;result.integral = "results.dat"<br>
} 
</span>
</tt>

<h3><a href="light1.dat">Light</a></h3>
<tt>
<span>
<br>
camera {<br>
&nbsp;camera.name  = "simple illumination";<br>
<br> 
# geometry<br>
&nbsp;geometry.perspective = TRUE;<br>
&nbsp;geometry.idealArea = 100000<br>
&nbsp;geometry.azimuth = 0.0;<br>
&nbsp;geometry.zenith = 0.0;<br>
&nbsp;geometry.twist = 0.0;<br>
&nbsp;geometry.lookAt = 0, 0, 0;<br>
&nbsp;geometry.boomLength = 10000.;<br>
} 
</span>
</tt>


<br>
In this way of describing the camera and lights, we imaging a camera with the focal point at a distance defined by the length of a boom (boomLength, here 10000. linear units) with a field of view viewing an area of 100000 units x 100000 units, with angles defined by zenith, azimuth and twist (all zero here).<p>

The camera and light geometries are identical, so we are viewing in a 'hot spot' scenario here (although as defined here, both the camera and light have finite fields of view).
<p>

The other terms in the camera file refer to output file names and modes of output. <tt>result.samplingImage</tt> gives the name of the output image (if required). <tt>result.integral</tt> provides the name of the output integral (this is normally what we are interested in in such simulations), here <a href="results.dat">results.dat</a>. The term <tt>result.integral.mode</tt> controls the ordering of the (ASCII) data to be output into the file specified by <tt>result.integral</tt>. Here it is <tt>"scattering order"</tt> (other options are <tt>"waveband"</tt> - e.g. for spectral outputs or <tt>"distance"</tt>, typically used for lidar simulations as we shall see later). <p>

Sampling charecteristics are defined for the camera: here <tt>262144 x 64</tt> primary rays will be used (in a square pattern by default) with <tt>262144</tt> pixels (here, 512 x 512).<p>

<p>
We can produce a useful (bi-conical) reflectance simulation with the following command:<p>
<p>

<tt>
echo 14 camera1.dat light1.dat | start -v -sensor_wavebands wavebands.dat -m 200 -black test.obj
</tt>

<br>
<br>
The option 14 of <tt>start</tt> is used - this allows the names of the camera and illumination file to be given as the next arguments (<tt>camera1.dat</tt> and <tt>light1.dat</tt> here). The option <tt>-v</tt> is used to switch on verbose mode (level 0). The option <tt>-sensor_wavebands</tt> is followed by the name of an ASCII file that specifies the wavelengths at which to simulate (<tt><a href="wavebands.dat">wavebands.dat</a></tt> here). The option <tt>-m 200</tt> tells the code to perform ray intersection tests to a maximum depth of 200 interaction (if this is not given, the default is 1, i.e. first-order scattering only). The option <tt>-black</tt> switches off the diffuse illumination field (i.e. like a 'black' sky).<br><br>

This command might take a few minutes to run, but could be run faster by changing the <tt>samplingCharacteristics.rpp</tt> in the camera file to <tt>1</tt> instead of <tt>64</tt>.<p>

The image resulting from this simulation is (scaled 0.0 to 1.5) is:

<p>
<center>
<img src="cameraImage.gif">
</center> <p>

The 'grey' tone over the majority of the image is where the (at pixel) reflectance is 1.0. The white 'halo' effect if multiple scattering between the pheroid and the plane (remember that the reflectance of all objects here is 1.0).<p>
Note that the multiple scattered component still appears a little 'noisy' even with 64 rays per pixel (partly because we have enhanced it here).<p>

The <a href="results.dat">integral results</a> can be displayed as a function of scattering order:<p>

<center>
<img src="results.png">
</center> <p>

The first-order scattering here is 0.9990244 (not surprising for a prolate spheroid of reflectance 1.0). Second-order scattering is 6.778946e-04, but 3rd-order scattering is higher, at 5.958815e-03. This sort of bevaiour is quite typical of this sort of scenario (note that there are essentially twp modes of decay of reflectance with scattering order shown in the figure), but the behaviour for vegetation canopies tends to be simpler.<p>


To obtain the total reflectance, we simply add up the contributions as a function of scattering order (e.g. using <tt>awk</tt>):

<br><br>

<tt>
awk < results.dat '($1 != "#"){for(i=1;i<=nl;i++)sum[i]+=$(i+1)} ($2=="Wavelength:"){getline;nl=NF-1;for(i=1;i<=nl;i++)w[i]=$(i+1)} END{for(i=1;i<=nl;i++)print w[i],sum[i]}'<br>
1.650000e+03 1.01187<br>
2.060000e+03 1.01187<br>
</tt>

<br>


<h1 align="center">Simple object lidar test: lidar simulation</h1>


Now, to do a lidar simulation of this same scenario, we simply need to add a specification of the lidar to the camera file. In its simplest form, this is e.g.:<br><br>

<h3><a href="camera2.dat">Camera</a></h3>
<tt>
<span>
<br>
camera {<br>
&nbsp;camera.name  = "lidar camera";<br>
<br>
# geometry<br>
&nbsp;geometry.perspective = TRUE;<br>
&nbsp;geometry.idealArea = 100000<br>
&nbsp;geometry.azimuth = 0.0;<br>
&nbsp;geometry.zenith = 0.0;<br>
&nbsp;geometry.twist = 0.0;<br>
&nbsp;geometry.lookAt = 0, 0, 0;<br>
&nbsp;geometry.boomLength = 10000.;<br>
<br>
&nbsp;samplingCharacteristics.nPixels = 262144;<br>
&nbsp;samplingCharacteristics.rpp = 64;<br>
<br>
&nbsp;result.integral.mode = "distance"<br>
<br>
&nbsp;result.integral = "results_lidar.dat"<br>
<br>
&nbsp;lidar.nBins = 150<br>
&nbsp;lidar.binStart = 14000<br>
&nbsp;lidar.binStep = 1000<br>
}
</span>
</tt>
<br><br>

We recall that the maximum height of the spheroid is 3000 units. The camera is located at 10000 units, so the distance between camera and the top of the spheroid is 7000 units. The 'return' distance is the same, so the minimum distance is 14000 units.<br>

Thus, we start lidar sampling at 14000 units. The ground is at distance 10000 from camera and light, but with a perspecive camera (and light source) for lidar, the maximum distance to ground (viewing a region of linear dimension 100000 units) is sqrt(10000^2 + 50000^2) = 50990. The maximum return trip (for first-order scattering) then is twice this = 101980.4 units.<br>

If we wish sampling of 1000 units in the lidar, we need at least (101981 - 14000)/1000 = 88 sampling bins. We decide on 150 to account for other effects.<br> 
<br>
Note that this is rather an artificial scenario: we do not usually simulate sich wide field of view lidars, so fewer bins (that can be calculated from small angle approximations) are normally sufficient.<br><br>

A plot of the returned (first-order) waveform is shown.
<br>
<center>
<img src="lidarPlot.png">
</center>

An animation of the lidar waveform (on the red channel) is shown below:
<br>
<center>
<img src="anim.gif">
</center>


 

[<a href="lidar1.html">previous</a>] [<a href="lidar3.html">next</a>]
